{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8f2b8d",
   "metadata": {},
   "source": [
    "# PSP analysis \n",
    "\n",
    "In this note, we analyze a dataset for Progressive Supranuclear Palsy (PSP), which includes RNA-Seq data from 25 PSP patients and 16 controls with total of 102 transcriptom.\n",
    "\n",
    "- Our analysis begins with a 3-fold cross-validation using XGBoost, where we compute and plot the average AUC, specificity, sensitivity, and accuracy scores with standard deviation error bars.\n",
    "\n",
    "- We then compare XGBoost with other models such as Random Forest, CatBoost, and SVM. Our comparison reveals clear overfitting issues in Random Forest, CatBoost, and SVM.\n",
    "\n",
    "- To address this, we perform a 5-fold cross-validation and explore hyperparameters for these models, but the overfitting issue persists.\n",
    "\n",
    "- To mitigate this, we conduct feature importance selection to identify the top 30 genes based on the models previously mentioned, and focus on the common genes among these top selections, which total 5 genes.\n",
    "\n",
    "- We then apply Logistic Regression and\n",
    "\n",
    "- CatBoost based on these common genes, observing that while these models show high sensitivity, they exhibit lower specificity.\n",
    "\n",
    "- Finally, we investigate Lasso Regression and Ridge Regression as additional methods. We find that Lasso Regression effectively mitigates overfitting, whereas Ridge Regression continues to suffer from overfitting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672f9148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, accuracy_score, auc\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4d14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=Path(\"/Users/zainabnazari/Desktop/psp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ace1a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_tumor_data=pd.read_csv(path1/\"Normalized_mRNA_matrix_GSE198048_102_genes.txt\",delimiter='\\t')\n",
    "s_tumor_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918243c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X1 = s_tumor_data.drop(['ID', 'Class'], axis=1)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'COHORT' column\n",
    "label = label_encoder.fit_transform(s_tumor_data['Class'])\n",
    "\n",
    "# Set the label for parkinson's disease and healthy control\n",
    "s_tumor_data.loc[:, 'Class'] = label\n",
    "\n",
    "y = s_tumor_data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a432a",
   "metadata": {},
   "source": [
    "# Cross-Validation with XGBoost model\n",
    "Cross-validation with 3 folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1255ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - AUC: 0.5847953216374269, Specificity: 0.1111, Accuracy: 0.5714, Sensitivity: 0.7895\n",
      "Fold 2 - AUC: 0.5986842105263158, Specificity: 0.3750, Accuracy: 0.7407, Sensitivity: 0.8947\n",
      "Fold 3 - AUC: 0.6049382716049383, Specificity: 0.2222, Accuracy: 0.7037, Sensitivity: 0.9444\n",
      "Fold 4 - AUC: 0.8209876543209876, Specificity: 0.3333, Accuracy: 0.7407, Sensitivity: 0.9444\n",
      "Fold 5 - AUC: 0.5987654320987654, Specificity: 0.4444, Accuracy: 0.6296, Sensitivity: 0.7222\n",
      "Fold 6 - AUC: 0.6790123456790123, Specificity: 0.4444, Accuracy: 0.7037, Sensitivity: 0.8333\n",
      "Fold 7 - AUC: 0.4938271604938272, Specificity: 0.3333, Accuracy: 0.5926, Sensitivity: 0.7222\n",
      "\n",
      "Average AUC: 0.4938 (±0.0941)\n",
      "\n",
      "Average Specificity: 0.3234 (±0.1118)\n",
      "Average Accuracy: 0.6689 (±0.0650)\n",
      "Average Sensitivity: 0.8358 (±0.0887)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X1)\n",
    "\n",
    "# Define hyperparameters and seed\n",
    "hyperparameters = {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 15}\n",
    "seed = 42\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = XGBClassifier(**hyperparameters, seed=seed)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "specificities = []\n",
    "accuracies = []\n",
    "sensitivities = []\n",
    "auc_scores = []\n",
    "\n",
    "# Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "\n",
    "# Iterate through each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_scaled, y), start=1):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "     # Calculate specificity, accuracy, and sensitivity\n",
    "     # Calculate AU-ROC score\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sensitivity = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    specificities.append(specificity)\n",
    "    accuracies.append(accuracy)\n",
    "    sensitivities.append(sensitivity)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    # Print metrics for each fold\n",
    "    print(f'Fold {i} - AUC: {auc_score}, Specificity: {specificity:.4f}, Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}')\n",
    "\n",
    "# Print average and standard deviation of metrics\n",
    "average_auc_score = np.mean(auc_score)\n",
    "average_specificity = np.mean(specificities)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "average_sensitivity = np.mean(sensitivities)\n",
    "std_specificity = np.std(specificities)\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_sensitivity = np.std(sensitivities)\n",
    "std_auc_score = np.std(auc_scores)\n",
    "\n",
    "print(f'\\nAverage AUC: {average_auc_score:.4f} (±{std_auc_score:.4f})')\n",
    "print(f'\\nAverage Specificity: {average_specificity:.4f} (±{std_specificity:.4f})')\n",
    "print(f'Average Accuracy: {average_accuracy:.4f} (±{std_accuracy:.4f})')\n",
    "print(f'Average Sensitivity: {average_sensitivity:.4f} (±{std_sensitivity:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e7cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
